{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "# Decision tree model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A\n",
       "1    B\n",
       "2    A\n",
       "3    C\n",
       "4    B\n",
       "Name: Category, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    'Category': ['A', 'B', 'A', 'C', 'B', 'C', 'A', 'C', 'B', 'A'],\n",
    "    'NumericFeature1': [10, 15, 20, 25, 30, 35, 40, 45, 50, 55],\n",
    "    'NumericFeature2': [5, 8, 12, 16, 20, 24, 28, 32, 36, 40]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "test = df.pop('Category')\n",
    "#df.head()\n",
    "#test\n",
    "type(pd.DataFrame(test))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#pre-processing\n",
    "\n",
    "datacomb_new = pd.read_csv('data_allthreeyears_combined_new1.csv')\n",
    "categorical_columns = datacomb_new.select_dtypes(include=['object']).columns.tolist()\n",
    "datacomb_new = datacomb_new.drop('year', axis = 1) # drop year columns\n",
    "unique_counts = datacomb_new.nunique(dropna=False)\n",
    "\n",
    "binary_cols = unique_counts[unique_counts <= 2].index.tolist()\n",
    "non_binary_cols = unique_counts[unique_counts > 2].index.tolist()\n",
    "\n",
    "datacomb_new[binary_cols] = np.where((datacomb_new[binary_cols] != 0) & (~datacomb_new[binary_cols].isna()), 1, 0)\n",
    "datacomb_new = datacomb_new.dropna(subset = ['Job_title - Selected Choice'])\n",
    "\n",
    "Job_title = datacomb_new.pop('Job_title - Selected Choice')\n",
    "datacomb_new.insert(len(datacomb_new.columns), 'Job_title - Selected Choice', Job_title)\n",
    "cols_to_drop = ['Job_No.OfDSTeamMember', 'Job_EmployerUsingML?','Money Spent on ML/Cloud Computing','Times used TPU', 'Job_title - Selected Choice']\n",
    "datacomb_new.drop(cols_to_drop, axis = 1, inplace = True)\n",
    "\n",
    "filtered_non_binary_cols = [item for item in non_binary_cols if item not in cols_to_drop]\n",
    "filtered_non_binary_cols\n",
    "\n",
    "datacomb_new_wo_Jtitle = datacomb_new\n",
    "\n",
    "\n",
    "# Encoding categorical features for X\n",
    "encoded_df = pd.get_dummies(datacomb_new_wo_Jtitle, columns = filtered_non_binary_cols)\n",
    "\n",
    "encoded_df.drop('Age_70+', axis = 1, inplace = True) # to remove multi-colinearity\n",
    "encoded_array = encoded_df.to_numpy()\n",
    "\n",
    "\n",
    "\n",
    "# Encoding labels in Y\n",
    "y_encoded = label_encoder.fit_transform(pd.DataFrame(Job_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'criterion': 'gini', 'max_depth': 7, 'max_features': 'auto', 'min_samples_leaf': 2, 'min_samples_split': 10}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=7, max_features='auto', min_samples_leaf=2,\n",
       "                       min_samples_split=10, random_state=42)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: X-Y dataset\n",
    "\n",
    "X = encoded_df\n",
    "y = Job_title\n",
    "\n",
    "# Step 2: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Step 3: Train a Decision Tree model\n",
    "decision_tree_model = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Use GridSearchCV to search for the best combination of hyperparameters\n",
    "grid_search = GridSearchCV(decision_tree_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Use the best model for predictions\n",
    "best_dt_model = grid_search.best_estimator_\n",
    "#y_pred = best_dt_model.predict(X_test)\n",
    "\n",
    "decision_tree_model = best_dt_model # update the model with the best parameter\n",
    "decision_tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36\n",
      "\n",
      "Classification Report:\n",
      "                                                                  precision    recall  f1-score   support\n",
      "\n",
      "                                                Business Analyst       0.00      0.00      0.00       159\n",
      "                                          Currently not employed       0.00      0.00      0.00       513\n",
      "                                           DBA/Database Engineer       0.00      0.00      0.00        41\n",
      "                                              Data Administrator       0.00      0.00      0.00         7\n",
      "                                                    Data Analyst       0.19      0.19      0.19       380\n",
      "Data Analyst (Business, Marketing, Financial, Quantitative, etc)       0.28      0.04      0.07       123\n",
      "                                                  Data Architect       0.00      0.00      0.00         5\n",
      "                                                   Data Engineer       0.00      0.00      0.00       127\n",
      "                                                  Data Scientist       0.38      0.59      0.46       833\n",
      "                                              Developer Advocate       0.00      0.00      0.00         7\n",
      "                                    Developer Relations/Advocacy       0.00      0.00      0.00        17\n",
      "                                         Engineer (non-software)       0.00      0.00      0.00        40\n",
      "                                       Machine Learning Engineer       0.27      0.07      0.11       258\n",
      "                                Machine Learning/ MLops Engineer       0.33      0.02      0.03        56\n",
      "    Manager (Program, Project, Operations, Executive-level, etc)       0.00      0.00      0.00        77\n",
      "                                                           Other       0.25      0.15      0.19       503\n",
      "                                                 Product Manager       0.00      0.00      0.00        31\n",
      "                                         Product/Project Manager       0.00      0.00      0.00        82\n",
      "                                         Program/Project Manager       0.00      0.00      0.00        77\n",
      "                                              Research Scientist       0.30      0.09      0.14       346\n",
      "                                               Software Engineer       0.24      0.16      0.19       499\n",
      "                                                    Statistician       0.00      0.00      0.00        73\n",
      "                                                         Student       0.40      0.99      0.57      1241\n",
      "                                             Teacher / professor       0.33      0.02      0.04        93\n",
      "\n",
      "                                                        accuracy                           0.36      5588\n",
      "                                                       macro avg       0.12      0.10      0.08      5588\n",
      "                                                    weighted avg       0.25      0.36      0.26      5588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 4: Make predictions\n",
    "y_pred = decision_tree_model.predict(X_test)\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Print classification report for more detailed evaluation\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Now, you can use this trained model to make recommendations for new applicants\n",
    "# by providing their profile information as input to the trained decision tree model.\n",
    "# For example:\n",
    "\n",
    "# new_applicant_profile = pd.DataFrame({'encoded_skill': [label_encoder.transform(['Python'])[0]],\n",
    "#                                        'education_level': ['Bachelor'],\n",
    "#                                        'experience': [2]})\n",
    "\n",
    "# prediction = decision_tree_model.predict(new_applicant_profile)\n",
    "# print(f\"\\nPrediction for the new applicant: {prediction[0]}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
